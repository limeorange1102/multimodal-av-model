# ğŸ“¦ data_preprocessing.py (LandmarkEncoder ë²„ì „)
# nê°œì˜ ë‹¨ì¼í™”ì ì˜ìƒì—ì„œ nC2 ìŒì˜ ë©€í‹°í™”ì ìƒ˜í”Œ ìƒì„± + ì… landmark ì¢Œí‘œ ì‹œí€€ìŠ¤ ì €ì¥ + ë‹¨ì–´ í…ìŠ¤íŠ¸ ì €ì¥

import os
import cv2
import itertools
from glob import glob
from moviepy.editor import VideoFileClip, clips_array
from pydub import AudioSegment
import numpy as np
import json

from utils.landmark_utils import extract_mouth_landmarks  # âœ… ì™¸ë¶€ ìœ í‹¸ ëª¨ë“ˆì—ì„œ ì„í¬íŠ¸

# âœ… ê²½ë¡œ ì„¤ì •
input_dir = "input_videos"
output_root = "sample_pairs"
os.makedirs(output_root, exist_ok=True)

# âœ… ëª¨ë“  ì˜ìƒ íŒŒì¼ ê²½ë¡œ
video_paths = sorted(glob(os.path.join(input_dir, "*.mp4")))

# âœ… ì˜ìƒ ì´ë¦„ â†’ ë‹¨ì–´ ë ˆì´ë¸” ë¶ˆëŸ¬ì˜¤ê¸°
labels = {}
with open(os.path.join(input_dir, "labels.txt"), "r", encoding="utf-8") as f:
    for line in f:
        name, word = line.strip().split()
        labels[name] = word

# âœ… ì˜ìƒ ì¡°í•©
group_id = 0
for path1, path2 in itertools.combinations(video_paths, 2):
    name1 = os.path.splitext(os.path.basename(path1))[0]
    name2 = os.path.splitext(os.path.basename(path2))[0]
    word1 = labels.get(name1, "unknown")
    word2 = labels.get(name2, "unknown")

    group_folder = os.path.join(output_root, f"sample_{group_id:03d}")
    os.makedirs(group_folder, exist_ok=True)

    # âœ… Step 1: ì˜ìƒ ë³‘í•©
    clip1 = VideoFileClip(path1).resize(height=224)
    clip2 = VideoFileClip(path2).resize(height=224)
    min_w = min(clip1.w, clip2.w)
    clip1 = clip1.resize(width=min_w)
    clip2 = clip2.resize(width=min_w)

    merged_clip = clips_array([[clip1, clip2]])
    merged_path = os.path.join(group_folder, "combined.mp4")
    merged_clip.write_videofile(merged_path, codec="libx264", audio=True)

    # âœ… Step 2: í”„ë ˆì„ ë¶„ë¦¬ + ì…ëª¨ì–‘ landmark ì¶”ì¶œ
    cap = cv2.VideoCapture(merged_path)
    landmarks_A = []
    landmarks_B = []
    idx = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        H, W, _ = frame.shape
        mid = W // 2
        frame_A = frame[:, :mid]
        frame_B = frame[:, mid:]

        lm_A = extract_mouth_landmarks(frame_A)
        lm_B = extract_mouth_landmarks(frame_B)

        if lm_A:
            landmarks_A.append(lm_A)
        if lm_B:
            landmarks_B.append(lm_B)
        idx += 1
    cap.release()

    # landmark ì¢Œí‘œ ì €ì¥
    with open(os.path.join(group_folder, "landmarks_A.json"), "w", encoding="utf-8") as f:
        json.dump(landmarks_A, f)
    with open(os.path.join(group_folder, "landmarks_B.json"), "w", encoding="utf-8") as f:
        json.dump(landmarks_B, f)

    # âœ… Step 3: ì˜¤ë””ì˜¤ ë³‘í•©
    audio1 = AudioSegment.from_file(path1)
    audio2 = AudioSegment.from_file(path2)
    min_len = min(len(audio1), len(audio2))
    mixed = audio1[:min_len].overlay(audio2[:min_len])
    mixed.export(os.path.join(group_folder, "mixed.wav"), format="wav")

    # âœ… Step 4: ë¼ë²¨ ì €ì¥
    with open(os.path.join(group_folder, "gt_A.txt"), "w", encoding="utf-8") as f:
        f.write(word1 + "\n")
    with open(os.path.join(group_folder, "gt_B.txt"), "w", encoding="utf-8") as f:
        f.write(word2 + "\n")

    print(f"âœ… sample_{group_id:03d} ì™„ë£Œ")
    group_id += 1
